---------- Layer 6: torch.Size([4, 1])
[0.0, 0.0] -> [0.47064414620399475]
[1.0, 1.0] -> [0.3085978925228119]
[2.0, 2.0] -> [0.09834760427474976]
[-1.0, -1.0] -> [0.3085978925228119]











In [55]: runfile('/media/jpower/passport/jpower/Research/fuzzy/torch-fis/test.py')
---------- Layer 1: torch.Size([1, 2])
case 0: tensor([1., 1.])
tensor([[1., 1.]])
---------- Layer 2: torch.Size([1, 2, 4])
case 0, x0: [0.018740227445960045, 0.31696024537086487, 0.5655072331428528, 0.04181535169482231]
case 0, x1: [0.018740227445960045, 0.31696024537086487, 0.5655072331428528, 0.04181535169482231]
---------- Layer 3: torch.Size([1, 16])
tensor([[0.0004, 0.0059, 0.0106, 0.0008, 0.0059, 0.1005, 0.1792, 0.0133, 0.0106,
         0.1792, 0.3198, 0.0236, 0.0008, 0.0133, 0.0236, 0.0017]],
       grad_fn=<ProdBackward2>)
---------- Layer 4: torch.Size([1, 16])
tensor([[0.0004, 0.0067, 0.0119, 0.0009, 0.0067, 0.1130, 0.2016, 0.0149, 0.0119,
         0.2016, 0.3596, 0.0266, 0.0009, 0.0149, 0.0266, 0.0020]],
       grad_fn=<DivBackward0>)
---------- Layer 5: torch.Size([1, 16, 1])
[-0.05000000074505806, -0.05000000074505806] -1.399999976158142 [-1.5]
[-0.05000000074505806, -1.399999976158142] 0.10999999940395355 [-1.3399999141693115]
[-1.399999976158142, 0.10999999940395355] -0.10000000149011612 [-1.3899999856948853]
[0.10999999940395355, -0.10000000149011612] 1.2899999618530273 [1.2999999523162842]
[-0.10000000149011612, 1.2899999618530273] 0.10999999940395355 [1.2999999523162842]
[1.2899999618530273, 0.10999999940395355] 0.10000000149011612 [1.5]
[0.10999999940395355, 0.10000000149011612] 1.2899999618530273 [1.5]
[0.10000000149011612, 1.2899999618530273] -0.05000000074505806 [1.340000033378601]
[1.2899999618530273, -0.05000000074505806] 0.05000000074505806 [1.2899999618530273]
[-0.05000000074505806, 0.05000000074505806] -1.399999976158142 [-1.399999976158142]
[0.05000000074505806, -1.399999976158142] -0.10000000149011612 [-1.4500000476837158]
[-1.399999976158142, -0.10000000149011612] 0.10999999940395355 [-1.3899999856948853]
[-0.10000000149011612, 0.10999999940395355] 1.2899999618530273 [1.2999999523162842]
[0.10999999940395355, 1.2899999618530273] 0.17000000178813934 [1.5699999332427979]
[1.2899999618530273, 0.17000000178813934] 0.17000000178813934 [1.6299998760223389]
[0.17000000178813934, 0.17000000178813934] 0.3799999952316284 [0.7200000286102295]
---------- Layer 6: torch.Size([])
tensor(-0.2804, grad_fn=<SqueezeBackward0>)

In [56]: 
